{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Air Quality Data Analysis Project ‚Äî Final Documentation\n",
    "\n",
    "# üìå Project Overview\n",
    "\n",
    "This project analyzes air quality data in Vienna by combining historical air pollution data from a CSV dataset\n",
    "with live air quality measurements retrieved from the OpenWeatherMap API.\n",
    "The final dataset is cleaned, stored in MongoDB Atlas, and visualized in a Jupyter Notebook.\n",
    "This documentation outlines every step taken, including personal decisions and troubleshooting.\n",
    "\n",
    "\n",
    "# üîß Setup\n",
    "\n",
    "- Python Version: 3.11\n",
    "- Pandas Version: 1.5.3\n",
    "- Pymongo Version: 4.6.3\n",
    "- Jupyter (Dataspell)\n",
    "- MongoDB Atlas (NoSQL cloud database)\n",
    "\n",
    "\n",
    "# üåê Architecture\n",
    "\n",
    "- Local machine (Jupyter Notebook)\n",
    "- OpenWeatherMap API (Live data collection)\n",
    "- MongoDB Atlas (Data storage: collections `historical_data`, `live_data`)\n",
    "\n",
    "Flow: CSV ‚û° Pandas ‚û° Clean ‚û° MongoDB\n",
    "     API ‚û° JSON ‚û° Clean ‚û° MongoDB ‚û° Merge ‚û° Analysis\n"
   ],
   "id": "36a902d50821e47d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Load and clean historical CSV data",
   "id": "35e5b24e25c7689d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset with correct separator\n",
    "df = pd.read_csv('../data/AirQuality.csv', sep=';')\n",
    "\n",
    "# Combine Date and Time into a proper datetime column\n",
    "df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'].str.replace('.', ':', regex=False), dayfirst=True)\n",
    "\n",
    "# Set Datetime as index for time-based analysis\n",
    "df.set_index('Datetime', inplace=True)\n",
    "\n",
    "# Drop original Date and Time columns\n",
    "df.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "# Replace -200 with NaN\n",
    "df.replace(-200, pd.NA, inplace=True)\n",
    "\n",
    "# Only drop rows missing key air quality fields\n",
    "df_cleaned = df.dropna(subset=['CO(GT)', 'NOx(GT)', 'C6H6(GT)'])\n",
    "\n",
    "print(\"Data shape after cleaning:\", df_cleaned.shape)\n",
    "df_cleaned.head()\n"
   ],
   "id": "713e369bca8b34f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Note:\n",
    "After exploring the raw file, I noticed some values like -200 meant missing.\n",
    "I verified this from the documentation and used it to clean the dataset."
   ],
   "id": "b1d33b1c8597d767"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Fetch live data from OpenWeatherMap API\n",
    "\n",
    "- We now connect to the OpenWeatherMap API to fetch real-time air quality data for Vienna.\n",
    "- This step is important for linking historic data trends with live measurements.\n",
    "- The API response includes components such as CO, NO2, O3, etc.\n",
    "- I used the latitude and longitude for Vienna to ensure accurate data."
   ],
   "id": "6c8fea4518b69e85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:10:57.357654Z",
     "start_time": "2025-04-05T19:10:57.288645Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': 16.3721, 'lat': 48.2085}, 'list': [{'main': {'aqi': 3}, 'components': {'co': 240.33, 'no': 0, 'no2': 1.89, 'o3': 107.29, 'so2': 0.71, 'pm2_5': 5.79, 'pm10': 6.28, 'nh3': 4.62}, 'dt': 1743880243}]}\n"
     ]
    }
   ],
   "execution_count": 11,
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = \"08cc967af314d1c3cc5c6f66c23c73b1\"\n",
    "LAT, LON = 48.2082, 16.3738  # Vienna\n",
    "\n",
    "url = f\"http://api.openweathermap.org/data/2.5/air_pollution?lat={LAT}&lon={LON}&appid={API_KEY}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.json())"
   ],
   "id": "7eb84287342bf991"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:14:49.679505Z",
     "start_time": "2025-04-05T19:14:49.558631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "API_KEY = \"08cc967af314d1c3cc5c6f66c23c73b1\"\n",
    "LAT, LON = 48.2082, 16.3738\n",
    "\n",
    "url = f\"https://api.openweathermap.org/data/2.5/air_pollution?lat={LAT}&lon={LON}&appid={API_KEY}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Convert UNIX timestamp to readable format\n",
    "data = response.json()\n",
    "timestamp = data[\"list\"][0][\"dt\"]\n",
    "data[\"list\"][0][\"timestamp_readable\"] = datetime.utcfromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Save to file\n",
    "with open(\"../data/live_air_quality.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Live data saved to /data/live_air_quality.json\")\n"
   ],
   "id": "cd7702423df2521",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Live data saved to /data/live_air_quality.json\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Collect 24 samples hourly with loop",
   "id": "81adde0ee663d13b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T20:23:34.861863Z",
     "start_time": "2025-04-05T20:23:26.427874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# CONFIG\n",
    "API_KEY = \"08cc967af314d1c3cc5c6f66c23c73b1\"\n",
    "LAT, LON = 48.2082, 16.3738\n",
    "MONGO_URI = \"mongodb+srv://air_user:airuserpassword@airqualitycluster.uzyb6qb.mongodb.net/?retryWrites=true&w=majority&appName=AirQualityCluster\"\n",
    "INTERVAL = 3600  # for testing: 60 seconds instead of 1 hour\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[\"air_quality_db\"]\n",
    "collection = db[\"live_data\"]\n",
    "\n",
    "print(\"üì° Starting live air quality collection loop...\")\n",
    "\n",
    "# Run the loop only a few times for notebook testing\n",
    "for i in range(24):  # <-- You can set this to 24 for 24 samples\n",
    "    try:\n",
    "        url = f\"https://api.openweathermap.org/data/2.5/air_pollution?lat={LAT}&lon={LON}&appid={API_KEY}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        record = data[\"list\"][0]\n",
    "        record[\"coord\"] = data[\"coord\"]\n",
    "        record[\"timestamp_unix\"] = record[\"dt\"]\n",
    "        record[\"timestamp\"] = datetime.fromtimestamp(record[\"dt\"], tz=timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        if collection.find_one({\"timestamp_unix\": record[\"timestamp_unix\"]}):\n",
    "            print(f\"‚ö†Ô∏è  Entry for {record['timestamp']} already exists. Skipping.\")\n",
    "        else:\n",
    "            collection.insert_one(record)\n",
    "            print(f\"‚úÖ Inserted data at {record['timestamp']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)\n",
    "\n",
    "    time.sleep(INTERVAL)\n"
   ],
   "id": "39d87f18d785294d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Starting live air quality collection loop...\n",
      "‚úÖ Inserted data at 2025-04-05 20:19:16\n",
      "‚úÖ Inserted data at 2025-04-05 21:23:31\n",
      "‚úÖ Inserted data at 2025-04-05 22:17:04\n",
      "‚úÖ Inserted data at 2025-04-05 23:23:32\n",
      "‚úÖ Inserted data at 2025-04-06 00:23:32\n",
      "‚úÖ Inserted data at 2025-04-06 01:23:32\n",
      "‚úÖ Inserted data at 2025-04-06 02:20:44\n",
      "‚úÖ Inserted data at 2025-04-06 03:23:32\n",
      "‚úÖ Inserted data at 2025-04-06 04:23:32\n",
      "‚úÖ Inserted data at 2025-04-06 05:23:33\n",
      "‚úÖ Inserted data at 2025-04-06 06:23:33\n",
      "‚úÖ Inserted data at 2025-04-06 07:23:33\n",
      "‚úÖ Inserted data at 2025-04-06 08:17:27\n",
      "‚úÖ Inserted data at 2025-04-06 09:23:33\n",
      "‚úÖ Inserted data at 2025-04-06 10:20:31\n",
      "‚úÖ Inserted data at 2025-04-06 11:23:23\n",
      "‚úÖ Inserted data at 2025-04-06 12:22:36\n",
      "‚úÖ Inserted data at 2025-04-06 13:17:33\n",
      "‚úÖ Inserted data at 2025-04-06 14:22:44\n",
      "‚úÖ Inserted data at 2025-04-06 15:23:34\n",
      "‚úÖ Inserted data at 2025-04-06 16:23:35\n",
      "‚úÖ Inserted data at 2025-04-06 17:23:35\n",
      "‚úÖ Inserted data at 2025-04-06 18:14:49\n",
      "‚úÖ Inserted data at 2025-04-06 19:20:22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 40\u001B[39m\n\u001B[32m     37\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m     38\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m‚ùå Error:\u001B[39m\u001B[33m\"\u001B[39m, e)\n\u001B[32m---> \u001B[39m\u001B[32m40\u001B[39m \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mINTERVAL\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Store to MongoDB Atlas",
   "id": "56ce228c99b525b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:40:47.741126Z",
     "start_time": "2025-04-05T19:40:39.193575Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data successfully uploaded to MongoDB!\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Replace with your actual connection string\n",
    "uri = \"mongodb+srv://air_user:airuserpassword@airqualitycluster.uzyb6qb.mongodb.net/?retryWrites=true&w=majority&appName=AirQualityCluster\"\n",
    "client = MongoClient(uri)\n",
    "\n",
    "# Connect to the database and collection\n",
    "db = client['air_quality_db']\n",
    "collection = db['historical_data']\n",
    "\n",
    "# Prepare DataFrame for MongoDB\n",
    "df_to_upload = df_cleaned.reset_index()  # Include Datetime as a column\n",
    "\n",
    "# Convert DataFrame to list of dictionaries\n",
    "data_dict = df_to_upload.to_dict(\"records\")\n",
    "\n",
    "# Insert into MongoDB\n",
    "collection.insert_many(data_dict)\n",
    "\n",
    "print(\"‚úÖ Data successfully uploaded to MongoDB!\")\n"
   ],
   "id": "6ec48e55acb79117"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T19:57:13.789930Z",
     "start_time": "2025-04-05T19:57:09.293042Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Live data inserted into MongoDB\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Load JSON\n",
    "with open('../data/live_air_quality.json') as f:\n",
    "    live_data = json.load(f)\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://air_user:airuserpassword@airqualitycluster.uzyb6qb.mongodb.net/?retryWrites=true&w=majority&appName=AirQualityCluster\")\n",
    "db = client['air_quality_db']\n",
    "collection = db['live_data']  # New collection\n",
    "\n",
    "# Insert\n",
    "collection.insert_one(live_data)\n",
    "print(\"‚úÖ Live data inserted into MongoDB\")\n"
   ],
   "id": "53a2c5e5377199d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Clean and flatten live data",
   "id": "204c52e535122134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T11:51:14.872563Z",
     "start_time": "2025-04-07T11:51:10.397794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://air_user:airuserpassword@airqualitycluster.uzyb6qb.mongodb.net/?retryWrites=true&w=majority&appName=AirQualityCluster\")\n",
    "db = client['air_quality_db']\n",
    "live_collection = db['live_data']\n",
    "\n",
    "# Load data into a DataFrame\n",
    "df_live = pd.DataFrame(list(live_collection.find()))\n",
    "\n",
    "# Drop rows with missing essential values\n",
    "df_live_cleaned = df_live.dropna(subset=[\"components\", \"timestamp\"])\n",
    "\n",
    "# Flatten the 'components' dictionary column into separate columns\n",
    "components_df = pd.json_normalize(df_live_cleaned[\"components\"])\n",
    "\n",
    "# Combine with original DataFrame\n",
    "df_live_cleaned = pd.concat([df_live_cleaned, components_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_live_cleaned.drop(columns=[\"_id\", \"coord\", \"list\", \"main\", \"components\"], inplace=True)\n",
    "\n",
    "# Show cleaned data\n",
    "df_live_cleaned.head()\n"
   ],
   "id": "4ab4166ae4a23881",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             dt  timestamp_unix            timestamp      co   no   no2  \\\n",
       "1  1.743884e+09    1.743884e+09  2025-04-05 20:14:28  247.00  0.0  2.40   \n",
       "2  1.743884e+09    1.743884e+09  2025-04-05 20:15:32  247.00  0.0  2.40   \n",
       "3  1.743884e+09    1.743884e+09  2025-04-05 20:19:16  250.34  0.0  2.91   \n",
       "4  1.743888e+09    1.743888e+09  2025-04-05 21:23:31  250.34  0.0  3.04   \n",
       "5  1.743891e+09    1.743891e+09  2025-04-05 22:17:04  250.34  0.0  3.00   \n",
       "\n",
       "       o3   so2  pm2_5  pm10   nh3  \n",
       "1  100.14  0.67   5.95  6.44  4.56  \n",
       "2  100.14  0.67   5.95  6.44  4.56  \n",
       "3   91.55  0.51   5.07  5.49  4.18  \n",
       "4   87.26  0.35   3.78  4.10  3.45  \n",
       "5   84.40  0.26   2.34  2.63  2.44  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>timestamp_unix</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>co</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "      <th>o3</th>\n",
       "      <th>so2</th>\n",
       "      <th>pm2_5</th>\n",
       "      <th>pm10</th>\n",
       "      <th>nh3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.743884e+09</td>\n",
       "      <td>1.743884e+09</td>\n",
       "      <td>2025-04-05 20:14:28</td>\n",
       "      <td>247.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>100.14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.44</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.743884e+09</td>\n",
       "      <td>1.743884e+09</td>\n",
       "      <td>2025-04-05 20:15:32</td>\n",
       "      <td>247.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>100.14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.44</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.743884e+09</td>\n",
       "      <td>1.743884e+09</td>\n",
       "      <td>2025-04-05 20:19:16</td>\n",
       "      <td>250.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.91</td>\n",
       "      <td>91.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>5.07</td>\n",
       "      <td>5.49</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.743888e+09</td>\n",
       "      <td>1.743888e+09</td>\n",
       "      <td>2025-04-05 21:23:31</td>\n",
       "      <td>250.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>87.26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.10</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.743891e+09</td>\n",
       "      <td>1.743891e+09</td>\n",
       "      <td>2025-04-05 22:17:04</td>\n",
       "      <td>250.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>84.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# üöÄ Git Versioning\n",
    "\n",
    "Git was initialized and commits were pushed after every major milestone:\n",
    "- Initial setup and CSV cleaning\n",
    "- API connection success\n",
    "- MongoDB upload\n",
    "- 24h sample collected\n",
    "\n",
    "Repo: https://github.com/YourUsername/bdinf-air-quality-project-main\n",
    "\n",
    "# üë• Multiuser Setup\n",
    "\n",
    "- All team members have access to the MongoDB Atlas cluster.\n",
    "- GitHub project shared with read/write access.\n",
    "- Code and data were structured clearly so anyone could clone and run the notebook.\n",
    "\n",
    "\n",
    "# üìå Conclusion / Story\n",
    "\n",
    "The goal of this project was to connect historical pollution data with live conditions in Vienna.\n",
    "By collecting 24 hourly samples, I enabled meaningful comparison and trend detection.\n",
    "This also simulates basic Big Data architecture by applying the 4V principles:\n",
    "- Volume: Thousands of rows from historical + live data.\n",
    "- Velocity: Hourly live updates.\n",
    "- Variety: CSV vs JSON structure.\n",
    "- Veracity: Cleaned and verified against -200 values.\n"
   ],
   "id": "a761b2ff279f54fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Air Quality)",
   "language": "python",
   "name": "air-quality-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
